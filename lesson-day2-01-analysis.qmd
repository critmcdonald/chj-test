---
title: "Lesson Day 2 Analysis"
author: "Christian McDonald"
---

> in mid-draft

## Goals of this lesson

For this lesson we'll learn about data wrangling functions, many of them from [dplyr](https://dplyr.tidyverse.org/index.html). These are the functions that are much like you do in spreadsheets, like filtering, pivoting and the like. Most of these skills are necessary to prepare data before you make charts.

Function we will learn about include: `arrange()`, `filter()`, `slice()`, `group_by()` and `summarize()`.

We'll use these to find several findings from our data, including:

- The coldest and warmest days
- The rainiest and snowiest days
- Years with most snow days
- Years with most 100+ days
- Years with most rain
- Earliest day to reach 100+ each year

To perhaps avoid some confusion we'll use just the Texas data for this lesson.

(You theoretically could use a different state, but would need to adjust your code to import the right data, use valid cities, etc.)

## Clean up our workspace

Again I have a practice notebook ready for you to fill in to keep you on track. Let's open the file and clean up our environment before we get going.

1. Open your `chjr-part1` project if it isn't already.
2. Open the file `practice-day1-analysis.qmd`.
3. Under run, choose "Restart R and Clear Output".
4. Check your Enfironment tab. If there is anything listed there, click on the **broom icon** to clear it out.

We do this so we don't have any leftovers from our previous notebook. Each notebook should run independently. That's also necessary to Render pages within a project.

## Add your setup chunk

I'm going to include the whole setup chunk code here again so you get the execution options.

```{r}
#| label: setup
#| message: false
#| echo: fenced

library(tidyverse)
```

We only need the tidyverse library for this one.

## Import our cleaned data

Now to reap the benefit our the hard work from last lesson, let's import our cleaned data.

1. In the import section of the notebook, add a code chunk.
2. Add the `read_rds()` function below and fill out the path to your cleaned data, as indicated.
3. Save that data into a new object called `tx_clean`.

```{r}
tx_clean <- read_rds("data-processed/tx_clean.rds")
```

## Arrange

The [arrange()](https://dplyr.tidyverse.org/reference/arrange.html) function is what we use to sort our data. We can use this function to find a couple of answers were looking for, like what are the hottest and coldest days in our data.

The function is pretty simple, just feed it the data (usually from a pipe) and then add the column you want to sort on. By default it is in "ascending" order: low to high or alphabetically. If you want the opposite (and journalists usually do) you have to wrap the column in another function, `desc()`.

1. In the arrange section, add a code chunk for the "Coldest day" section.
2. Start with your data, the pipe into `arrange()` and add the `tmin()` column.
3. **Run the chunk** so you can see the result. Note the data is ordered by the tmin column, but it's hard to see. Let's add a `select()` function to focus on what we care about.
4. Pipe into `select()` adding the city, date and tmin columns.

```{r}
tx_clean |> 
  arrange(tmin) |> 
  select(city, date, tmin)
```

Glad I as not in Austin in 1949. Now to find the hottest days.

1. After the "Hottest day" header add a new code chunk.
2. Use arrange to find the highest `tmax` value. **Run** the chunk to make sure it worked.
3. Use select to clean up the fields.

```{r}
tx_clean |>
  arrange(desc(tmax)) |> 
  select(city, date, tmax)
```

Ugh, I was in Austin in 2011.

### OYO: Most rain

Using the same tools, find:

- The days with the most rain
- The days with the most snow

## Filter

We use the [filter()](https://dplyr.tidyverse.org/reference/filter.html) function when we want to specify rows based on a condition. This is the equivalent of clicking on the Filter tool in Excel and choosing values to keep or exclude, but we do it with code that can be fixed and repeated.

We'll use this function to build to some of our answers, like which years had the most 100+ degree days. We need to work on this skill here first, as there are nuances.

The function works like this:

``` r
# this is psuedo code. don't add it
data |> 
  filter(variable comparison value)

# example
tx_clean |> 
  filter(city == "Austin")
```

The `filter()` function typically works in this order:

-   What is the variable (or column) you are searching in.
-   What is the comparison you want to do. Equal to? Greater than?
-   What is the observation (or value in the data) you are looking for?

Note the two equals signs `==` in our Austin example above. It is important to use two of them when you are asking if a value is "true" or "equal to", as a single `=` typically means you are assigning a value to something.

### Comparisons: Logical tests

There are a number of these logical tests for the comparison:

| Operator          | Definition               |
|:------------------|:-------------------------|
| x **\<** y        | Less than                |
| x **\>** y        | Greater than             |
| x **==** y        | Equal to                 |
| x **\<=** y       | Less than or equal to    |
| x **\>=** y       | Greater than or equal to |
| x **!=** y        | Not equal to             |
| x **%in%** c(y,z) | In a group               |
| **is.na(**x**)**  | Is NA (missing values)   |
| **!is.na(**x**)** | Is not NA                |

Where you apply a filter matters. If we want to consider only certain data before other operations, then we need to do the filter first. In other cases we may filter after all our calculations just to clean up the result to show rows of interest.

### Single condition

Let's find days that are 100+.

1. In the `## Filter` section in the part about 100+ days, add a code chunk.
2. Start with the data, the pipe into filter
3. For the condition, look in the `tmax` column using `>=` to find values "greater or equal to" `100`
4. **Run the code** to make sure it works.
5. Use `select()` to focuse on the variables of interest.

```{r}
tx_clean |> 
  filter(tmax >= 100) |> 
  select(city, date, tmax)
```

### Multiple "and" conditions

OK, that's fine, but our list is not long enough to see the days in Dallas. Let's do this again, but add a second condition to test. When you use a comma `,` or ampersand `&` between conditions, both conditions must be true to keep the rows.

1. In the Dallas 100+ section, start a new code chunk.
2. Do the same code as above and **run** it to make sure it still works.
3. Use a comma after the first condition to add a second one: `city == "Dallas"`.


```{r}
tx_clean |> 
  filter(tmax >= 100, city == "Dallas") |> 
  select(city, date, tmax)
```

### Multiple "or" conditions

But what if we have an "either or" case where one of two conditions could be true. This would be the case if we wanted to find days where it either a) snowed that day, or b) there was snow left on the ground from a previous day. This is a true snow day, right?

You can use the `|` operator for an "or" condition. That character is the shift of the `\` key just above your return/enter key.

1. In the section about snow days, add a chunk.
2. Add the code, but run after adding the first condition, before you add the second, so you can compare them when you are done.


```{r}
tx_clean |> 
  filter(snow > 0 | snwd > 0) |> 
  select(city, date, snow, snwd)
```

### But I need "and" and "or"

You can mix "and" and "or" conditions, but note the order of them might matter depending on what you are doing.

### OYO: Real snow days in Dallas

In your notebook, start with the snow days we had above, but add a new condition to it that 

### Filtering text

Our data here doesn't lend itself well to explaining this, but we can use filter to find parts of words as well. There are many ways, but the one I use the most is `str_detect()`.

```{r}
tx_clean |> 
  filter(str_detect(city, "st")) |> # <1>
  distinct(city)
```

1. Inside the filter, we start with `str_detect()`. The first argument it needs is which column in our data to look at, so we fed it `city`. The second argument (after a comma) is the string of text we are looking for in the column, which is `st` in our case.
2. I used `distinct(city)` here so we could more easily see our results.

The code above found both "Hou**st**on" and "Au**st**in" because they have "st" in them. It didn't capture "Dallas".

## Slice

Another way to pick out specific rows of data based on a condition is to use [slice](https://dplyr.tidyverse.org/reference/slice.html) variables like `slice_max()`, `slice_min()`. I mainly want to show this so you can understand our next function better.

Let's use `slice_min()` to find the coldest day in our data.

1. In the slice section of the notebook about coldest day, add the following:

```{r}
tx_clean |> 
  slice_min(tmin) |> 
  select(city, date, tmin)
```


We get one result, the coldest day in the data. But what if we want the coldest day for each city? We will introduce `group_by()` to solve that.

## Group by

The `group_by()` function goes behind the scenes to organize your data into groups, and any function that follows it gets executed **within** those groups.

The columns you feed into `group_by()` determine the groups. If we do `group_by(city)` then  all the "Austin" rows are grouped together, then all the "Dallas" rows, then all the "Houston" rows.

I sometimes think of these groups as piles of data, separate from each other. We would have three piles of date, one for each city. Functions that follow happen independently on each pile.

## Group and slice

If we add our `group_by(city)` before slice, then it works **within** each group. Like this:

```{r}
tx_clean |> 
  group_by(city) |> 
  slice_min(tmin) |> 
  select(city, date, tmin)
```

Look at the difference in this result. Now we get a result for each city, because the rows we "grouped" the data **before** performing the slice. Since there are three cities, we get three results.

## Multiple groupings

We can also group by multiple columns. What that does is create a group (or pile!) of data for each matching combination of values.

So, if we `group_by(city, yr)` then we will get a pile for each year of Austin (85 piles because there are 85 years of data for Austin), then a pile for each year in Houston, etc.

If we were to find the hottest day in each of those piles, it would look like this:

1. Create a new chunk and add this to your notebook.
2. Try it with and without the `distinct()` at the end and think about why you got those results.

```{r}
tx_clean |> 
  group_by(yr, city) |> 
  slice_max(tmax) |> 
  select(city, tmax) |> 
  distinct()
```

I added distinct the `distinct()` there to remove some ties where there were multiple days in a year with that high temperature.

## Summarize

While slice is nice, we really went through this exercise to understand group_by so we can use it with [summarize](https://dplyr.tidyverse.org/reference/summarise.html), which allows us to summarize data much like a pivot table in Excel.

::: callout-tip
`summarise()` and `summarize()` are the same function. The creator of tidyverse is from New Zealand so he has both spellings. I tend to use them both by whim, though the "s" version comes first in type-assist.
:::

If there are no group_by variables, the output will be a single row summarizing all observations in the input. If we have groups, it will contain one column for each grouping variable and one column for each summary statistic we specify.

Let's do one without groups.

1. In the Summarize section, add the following chunk and code.

```{r}
tx_clean |> 
  summarize(
    e_date = min(date),
    l_date = max(date),
    cnt = n()
  )
```

We have no groups here, so we just get the stats we as for ... the earliest date in our data, the latest date in our data and the number of rows.

### Add city as a group

1. Just use the copy-to-clipboard tool to add this to your notebook and run it to see it.

```{r}
tx_clean |> 
  group_by(city) |> # <1>
  summarise(
    e_date = min(date),
    l_date = max(date),
    cnt = n()
  )
```

1. This is where we add the group.

### Add both city and yr as a group

```{r}
tx_clean |> 
  group_by(city, yr) |> # <1>
  summarise(
    e_date = min(date),
    l_date = max(date),
    cnt = n()
  )
```

1. This is where we add the second group to get both city and yr.

### Common summarize stats

There are a number of statistics we can find about our data within summarize.

- `n()` counts the number of rows
- `n_distinct()` counts the number of distinct values in the column
- `min()` gives the smallest value
- `max()` gives the largest value

Some math operators might need the argument `na.rm = TRUE` to ignore NA (empty) values.

- `sum()` adds values together.
- `mean()` gives the mean (or average) value.
- `median()` gives the median or middle value

There are other useful ones in the [summarise documentation](https://dplyr.tidyverse.org/reference/summarise.html).

## Group and summarize: Count

### OYO: Most snow days by city each year

## Group and Summarize: Math

### OYO: Years with most snow

## Working through logic

## Challenge: Earliest 100+ day each city

